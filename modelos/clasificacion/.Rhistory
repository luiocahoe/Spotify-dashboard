# Recoger y mostrar las métricas de la validación cruzada
resultados_cv %>%
collect_metrics()
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_lm_final=lm_wf %>%
last_fit(particion)
# Mostrar matriz de confusión
modelo_lm_final %>%
collect_metrics()
modelo_rf_reg_final %>%
collect_predictions()
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_class=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_class %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
rf_spec=rand_forest(trees=tune(),
min_n=tune()) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Crear una receta para preprocesar los datos
preprocesado=recipe(streams ~ .,datos_modelo_class) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
rf_reg_wf=
workflow() %>%
add_model(rf_spec) %>%
add_recipe(preprocesado)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg <- vfold_cv(datos_ent, v = 10, strata = mode)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_reg <- expand_grid(trees=seq(100,200,by=50),
min_n=seq(2,8,by=2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_reg <- rf_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_rf_reg)
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_class=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_class %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
rf_spec=rand_forest(trees=tune(),
min_n=tune()) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Crear una receta para preprocesar los datos
preprocesado=recipe(streams ~ .,datos_modelo_class) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
rf_reg_wf=
workflow() %>%
add_model(rf_spec) %>%
add_recipe(preprocesado)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg <- vfold_cv(datos_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_reg <- expand_grid(trees=seq(100,200,by=50),
min_n=seq(2,8,by=2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_reg <- rf_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_rf_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_rf_reg %>%
collect_metrics()
# Mostrar matriz de confusión
modelo_rf_reg_final %>%
collect_metrics()
rf_reg_mejor=resultados_tune_rf_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
rf_reg_wfl_final <- rf_reg_wf %>%
finalize_workflow(rf_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_rf_reg_final <- rf_reg_wfl_final %>%
last_fit(particion)
# Mostrar matriz de confusión
modelo_rf_reg_final %>%
collect_metrics()
modelo_rf_reg_final %>%
collect_predictions()
# Mostrar matriz de confusión
modelo_rf_reg_final %>%
collect_metrics()
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_class=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_class %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
lm_spec=linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
preprocesado=recipe(streams ~ .,datos_modelo_class) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lm_wf=
workflow() %>%
add_model(lm_spec) %>%
add_recipe(preprocesado)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg=vfold_cv(datos_ent, v = 10)
# Ajustar el modelo con validación cruzada en el conjunto de entrenamiento
resultados_cv <- lm_wf %>%
fit_resamples(
resamples = cv_folds_reg
)
# Recoger y mostrar las métricas de la validación cruzada
resultados_cv %>%
collect_metrics()
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_lm_final=lm_wf %>%
last_fit(particion)
# Mostrar matriz de confusión
modelo_lm_final %>%
collect_metrics()
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_class=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_class %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
svm_spec=svm_rbf(cost=tune(),rbf_sigma=tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
svm_reg_spec=svm_rbf(cost=tune(),rbf_sigma=tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
preprocesado=recipe(streams ~ .,datos_modelo) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_pca(all_predictors(), num_comp = 5)
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_reg %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
svm_reg_spec=svm_rbf(cost=tune(),rbf_sigma=tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
preprocesado=recipe(streams ~ .,datos_modelo) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_pca(all_predictors(), num_comp = 5)
preprocesado=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_pca(all_predictors(), num_comp = 5)
# Definir el workflow que une la receta y el modelo
svm_wf=
workflow() %>%
add_model(svm_spec) %>%
add_recipe(preprocesado)
# Definir el workflow que une la receta y el modelo
svm_reg_wf=
workflow() %>%
add_model(svm_reg_spec) %>%
add_recipe(preprocesado)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg <- vfold_cv(datos_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_svm_reg <- expand_grid(cost = 3^(1:4), rbf_sigma = 3^(-5:-2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_svm_reg <- svm_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_svm_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_svm_reg %>%
collect_metrics()
svm_reg_mejor=resultados_tune_svm_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
svm_reg_wfl_final <- svm_reg_wf %>%
finalize_workflow(svm_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_svm_reg_final <- svm_reg_wfl_final %>%
last_fit(particion)
# Mostrar matriz de confusión
modelo_svm_reg_final %>%
collect_metrics()
rm(list=ls())
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion = datos_modelo_reg %>%
initial_split()
datos_ent= particion %>% training()
datos_test= particion %>% testing()
svm_reg_spec=svm_rbf(cost=tune(),rbf_sigma=tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
preprocesado=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
svm_reg_wf=
workflow() %>%
add_model(svm_reg_spec) %>%
add_recipe(preprocesado)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg <- vfold_cv(datos_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_svm_reg <- expand_grid(cost = 3^(1:4), rbf_sigma = 3^(-5:-2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_svm_reg <- svm_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_svm_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_svm_reg %>%
collect_metrics()
svm_reg_mejor=resultados_tune_svm_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
svm_reg_wfl_final <- svm_reg_wf %>%
finalize_workflow(svm_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_svm_reg_final <- svm_reg_wfl_final %>%
last_fit(particion)
# Mostrar matriz de confusión
modelo_svm_reg_final %>%
collect_metrics()
# Cargar las bibliotecas necesarias
library(tidyverse)
library(arrow)
library(tidymodels)
library(tune)
library(ranger)
library(dials)
# Leer los datos desde un archivo Feather
datos = read_feather("datos.feather")
# Preprocesar los datos
datos_modelo = datos %>%
select(-"__index_level_0__") %>%
rename_with(~ str_replace(., "_%", ""), contains("_%")) %>%
mutate(mode = as.factor(mode)) %>%
select(-c(1:16))
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123) # Para reproducibilidad
particion_class = initial_split(datos_modelo, prop = 0.8)
datos_entrenamiento = training(particion_class)
datos_prueba = testing(particion_class)
# Definir especificaciones del modelo Random Forest con parámetros a tunear
rf_class_spec = rand_forest(
mtry = tune(),
min_n = tune(),
trees = 1000  # Número de árboles fijo
) %>%
set_engine("randomForest") %>%
set_mode("classification")
# Crear una receta para preprocesar los datos
preprocesado_class = recipe(mode ~ ., datos_modelo) %>%
step_zv(all_numeric()) %>%
step_normalize(all_numeric())
# Definir el workflow que une la receta y el modelo
rf_class_wfl = workflow() %>%
add_recipe(preprocesado_class) %>%
add_model(rf_class_spec)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_class = vfold_cv(datos_entrenamiento, v = 10, strata = mode)
# Definir los rangos de hiperparámetros a explorar
mtry_values = seq(2, ncol(datos_entrenamiento) - 1, by = 2)
min_n_values = seq(2, 22, by = 4)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_class = expand_grid(mtry = mtry_values, min_n = min_n_values)
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_class = rf_class_wfl %>%
tune_grid(
resamples = cv_folds_class,
grid = grid_rf_class,
metrics = metric_set(roc_auc, accuracy)
)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_rf_class %>%
collect_metrics()
rf_class_mejor=resultados_tune_rf_class %>%
select_best(metric="accuracy")
# Finalizar el modelo con los mejores hiperparámetros
rf_class_wfl_final = rf_class_wfl %>%
finalize_workflow(rf_class_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_rf_class_final = rf_class_wfl_final %>%
last_fit(particion_class)
# Mostrar matriz de confusión
modelo_rf_class_final %>%
collect_predictions() %>%
conf_mat(truth = mode, estimate = .pred_class)
# Mostrar métricas de clasificación
modelo_rf_class_final %>%
collect_predictions() %>%
metrics(truth = mode, estimate = .pred_class)
# Generar y visualizar la curva ROC
modelo_rf_class_final %>%
collect_predictions() %>%
roc_curve(truth = mode, .pred_Major) %>%
autoplot()
modelo_rf_class_final %>%
extract_fit_engine() %>%
autoplot
library(randomForest)
modelo_rf_class_final %>%
extract_fit_engine() %>%
autoplot
# Convertir datos de entrenamiento a data.frame
datos_class_ent_rf <- as.data.frame(datos_class_ent)
# Cargar las bibliotecas necesarias
library(tidyverse)
library(arrow)
library(tidymodels)
library(tune)
library(ranger)
library(dials)
# Leer los datos desde un archivo Feather
datos = read_feather("datos.feather")
# Preprocesar los datos
datos_modelo = datos %>%
select(-"__index_level_0__") %>%
rename_with(~ str_replace(., "_%", ""), contains("_%")) %>%
mutate(mode = as.factor(mode)) %>%
select(-c(1:16))
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123) # Para reproducibilidad
particion_class = initial_split(datos_modelo, prop = 0.8)
datos_class_ent = training(particion_class)
datos_class_test = testing(particion_class)
# Definir especificaciones del modelo Random Forest con parámetros a tunear
rf_class_spec = rand_forest(
mtry = tune(),
min_n = tune(),
trees = 1000  # Número de árboles fijo
) %>%
set_engine("randomForest") %>%
set_mode("classification")
# Crear una receta para preprocesar los datos
preprocesado_class = recipe(mode ~ ., datos_modelo) %>%
step_zv(all_numeric()) %>%
step_normalize(all_numeric())
# Definir el workflow que une la receta y el modelo
rf_class_wfl = workflow() %>%
add_recipe(preprocesado_class) %>%
add_model(rf_class_spec)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_class = vfold_cv(datos_class_ent, v = 10, strata = mode)
# Definir los rangos de hiperparámetros a explorar
mtry_values = seq(2, ncol(datos_class_ent) - 1, by = 2)
min_n_values = seq(2, 22, by = 4)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_class = expand_grid(mtry = mtry_values, min_n = min_n_values)
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_class = rf_class_wfl %>%
tune_grid(
resamples = cv_folds_class,
grid = grid_rf_class,
metrics = metric_set(roc_auc, accuracy)
)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_rf_class %>%
collect_metrics()
rf_class_mejor=resultados_tune_rf_class %>%
select_best(metric="accuracy")
# Finalizar el modelo con los mejores hiperparámetros
rf_class_wfl_final = rf_class_wfl %>%
finalize_workflow(rf_class_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_rf_class_final = rf_class_wfl_final %>%
last_fit(particion_class)
# Mostrar matriz de confusión
modelo_rf_class_final %>%
collect_predictions() %>%
conf_mat(truth = mode, estimate = .pred_class)
# Mostrar métricas de clasificación
modelo_rf_class_final %>%
collect_predictions() %>%
metrics(truth = mode, estimate = .pred_class)
# Generar y visualizar la curva ROC
modelo_rf_class_final %>%
collect_predictions() %>%
roc_curve(truth = mode, .pred_Major) %>%
autoplot()
# Convertir datos de entrenamiento a data.frame
datos_class_ent_rf <- as.data.frame(datos_class_ent)
# Entrenar el modelo Random Forest
set.seed(123)
modelo_rf <- randomForest(mode ~ ., data = datos_class_ent_rf, ntree = 1000)
# Extraer el primer árbol del modelo
arbol_1 <- getTree(modelo_rf, k = 1, labelVar = TRUE)
# Convertir el árbol extraído en un objeto rpart para visualizarlo
arbol_1_rpart <- randomForest::getTree(modelo_rf, k = 1, labelVar = TRUE)
arbol_1_rpart <- rpart::as.rpart(arbol_1)
# Graficar el árbol
rpart.plot(arbol_1_rpart, main = "Árbol 1 del Modelo Random Forest")
library(randomForest)
library(rpart)
library(rpart.plot)
# Convertir el árbol extraído en un objeto rpart para visualizarlo
arbol_1_rpart <- randomForest::getTree(modelo_rf, k = 1, labelVar = TRUE)
arbol_1_rpart <- rpart::as.rpart(arbol_1)
# Graficar el árbol
rpart.plot(arbol_1_rpart, main = "Árbol 1 del Modelo Random Forest")
# Convertir los datos de entrenamiento a data.frame
datos_class_ent_rf <- as.data.frame(datos_class_ent)
# Entrenar el modelo Random Forest
set.seed(123)
modelo_rf <- randomForest(mode ~ ., data = datos_class_ent_rf, ntree = 1000)
# Extraer el primer árbol del modelo
arbol_1 <- getTree(modelo_rf, k = 1, labelVar = TRUE)
# Convertir el árbol extraído a un objeto rpart
arbol_1_rpart <- as.rpart(arbol_1)
reticulate::repl_python()
```{r}
library(arrow)
library(dplyr)
library(GGally)
datos <- read_feather("datos.feather")
# Seleccionar las columnas que contienen "%" en su nombre
columnas_con_porcentaje <- datos %>% select(contains("%"))
# Crear el pairplot
ggpairs(columnas_con_porcentaje)
ggpairs(columnas_con_porcentaje,
upper = list(continuous = wrap("points", alpha = 0.8, color = "blue")),
lower = list(continuous = wrap("points", alpha = 0.8, color = "blue")),
diag = list(continuous = wrap("barDiag", alpha = 0.8, fill = "blue")))
ggpairs(columnas_con_porcentaje,
lower = list(continuous = wrap("points", alpha = 0.8, color = "blue")),
diag = list(continuous = wrap("barDiag", alpha = 0.8, fill = "blue")))
ggpairs(columnas_con_porcentaje,
lower = list(continuous = wrap("points", alpha = 0.2, color = "blue")),
diag = list(continuous = wrap("barDiag", fill = "blue")))
