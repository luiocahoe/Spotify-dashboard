resultados_lm_cv %>%
collect_metrics()
modelo_lm_reg=lm_wf %>%
last_fit(particion_reg)
modelo_lm_reg %>%
collect_metrics()
save.image("~/Documents/4Estadistica/IAE/IAE2024_mio/Trabajo/complementario/Modelos_reg.RData")
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
lm_reg_spec=linear_reg() %>%
set_engine("lm_reg") %>%
set_mode("regression")
lm_reg_spec=linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lm_reg_wf=
workflow() %>%
add_model(lm_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg=vfold_cv(datos_reg_ent, v = 10)
# Ajustar el modelo con validación cruzada en el conjunto de entrenamiento
resultados_lm_reg_cv <- lm_reg_wf %>%
fit_resamples(
resamples = cv_folds_reg
)
# Recoger y mostrar las métricas de la validación cruzada
resultados_lm_reg_cv %>%
collect_metrics()
modelo_lm_reg_reg=lm_reg_wf %>%
last_fit(particion_reg)
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
lm_reg_spec=linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lm_reg_wf=
workflow() %>%
add_model(lm_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg=vfold_cv(datos_reg_ent, v = 10)
# Ajustar el modelo con validación cruzada en el conjunto de entrenamiento
resultados_lm_reg_cv <- lm_reg_wf %>%
fit_resamples(
resamples = cv_folds_reg
)
# Recoger y mostrar las métricas de la validación cruzada
resultados_lm_reg_cv %>%
collect_metrics()
modelo_lm_reg=lm_reg_wf %>%
last_fit(particion_reg)
modelo_lm_reg %>%
collect_metrics()
library(tidyverse)
library(arrow)
library(tidymodels)
library(vip)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
rf_spec=rand_forest(trees=tune(),
min_n=tune()) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Crear una receta para preprocesar los datos
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
library(tidyverse)
library(arrow)
library(tidymodels)
library(vip)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
rf_reg_spec=rand_forest(trees=tune(),
min_n=tune()) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Crear una receta para preprocesar los datos
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
rf_reg_wf=
workflow() %>%
add_model(rf_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg = vfold_cv(datos_reg_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_reg = expand_grid(trees=seq(100,200,by=50),
min_n=seq(2,8,by=2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_reg = rf_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_rf_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_rf_reg %>%
collect_metrics()
rf_reg_mejor=resultados_tune_rf_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
rf_reg_wfl_final = rf_reg_wf %>%
finalize_workflow(rf_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_rf_reg_final = rf_reg_wfl_final %>%
last_fit(particion_reg)
# Mostrar matriz de confusión
modelo_rf_reg_final %>%
collect_metrics()
modelo_rf_reg_final %>%
extract_fit_engine() %>%
vip()
library(tidyverse)
library(arrow)
library(tidymodels)
library(vip)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
svm_reg_spec=svm_rbf(cost=tune(),rbf_sigma=tune()) %>%
set_engine("kernlab") %>%
set_mode("regression")
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
svm_reg_wf=
workflow() %>%
add_model(svm_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg <- vfold_cv(datos_reg_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_svm_reg <- expand_grid(cost = 3^(1:4), rbf_sigma = 3^(-5:-2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_svm_reg <- svm_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_svm_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_svm_reg %>%
collect_metrics()
svm_reg_mejor=resultados_tune_svm_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
svm_reg_wfl_final <- svm_reg_wf %>%
finalize_workflow(svm_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_svm_reg_final <- svm_reg_wfl_final %>%
last_fit(particion_reg)
# Mostrar matriz de confusión
modelo_svm_reg_final %>%
collect_metrics()
library(tidyverse)
library(arrow)
library(tidymodels)
library(vip)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
rf_reg_spec=rand_forest(trees=tune(),
min_n=tune()) %>%
set_engine("randomForest") %>%
set_mode("regression")
# Crear una receta para preprocesar los datos
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
# Definir el workflow que une la receta y el modelo
rf_reg_wf=
workflow() %>%
add_model(rf_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg = vfold_cv(datos_reg_ent, v = 10)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_reg = expand_grid(trees=seq(100,200,by=50),
min_n=seq(2,8,by=2))
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_reg = rf_reg_wf %>%
tune_grid(
resamples = cv_folds_reg,
grid = grid_rf_reg)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_tune_rf_reg %>%
collect_metrics()
rf_reg_mejor=resultados_tune_rf_reg %>%
select_best(metric="rsq")
# Finalizar el modelo con los mejores hiperparámetros
rf_reg_wfl_final = rf_reg_wf %>%
finalize_workflow(rf_reg_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_rf_reg_final = rf_reg_wfl_final %>%
last_fit(particion_reg)
# Mostrar matriz de confusión
modelo_rf_reg_final %>%
collect_metrics()
modelo_rf_reg_final %>%
extract_fit_engine() %>%
vip()
library(tidyverse)
library(arrow)
library(tidymodels)
datos=read_feather("datos.feather")
datos=datos %>%
select(-"__index_level_0__")
datos_modelo_reg=datos %>%
select(-c("released_year",
"released_month",
"released_day",
"track_name",
"artist(s)_name"))
particion_reg = datos_modelo_reg %>%
initial_split()
datos_reg_ent= particion_reg %>% training()
datos_reg_test= particion_reg %>% testing()
lm_reg_spec=linear_reg() %>%
set_engine("lm") %>%
set_mode("regression")
preprocesado_reg=recipe(streams ~ .,datos_modelo_reg) %>%
step_novel(all_nominal()) %>%
step_dummy(all_nominal()) %>%
step_zv(all_predictors()) %>%
step_normalize(all_predictors())
lm_reg_wf=
workflow() %>%
add_model(lm_reg_spec) %>%
add_recipe(preprocesado_reg)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_reg=vfold_cv(datos_reg_ent, v = 10)
# Ajustar el modelo con validación cruzada en el conjunto de entrenamiento
resultados_lm_reg_cv <- lm_reg_wf %>%
fit_resamples(
resamples = cv_folds_reg
)
# Recoger y mostrar las métricas de la validación cruzada
resultados_lm_reg_cv %>%
collect_metrics()
modelo_lm_reg=lm_reg_wf %>%
last_fit(particion_reg)
modelo_lm_reg %>%
collect_metrics()
save.image("~/Documents/4Estadistica/IAE/IAE2024_mio/Trabajo/complementario/Modelos_reg.RData")
load("~/Documents/4Estadistica/IAE/IAE2024_mio/Trabajo/complementario/Modelos_reg.RData")
load("complementario/Modelos_reg.RData")
load("/complementario/Modelos_reg.RData")
load("./complementario/Modelos_reg.RData")
# Cargar las bibliotecas necesarias
library(tidyverse)
library(arrow)
library(tidymodels)
# Leer los datos desde un archivo Feather
datos = read_feather("datos.feather")
# Preprocesar los datos
datos_modelo_class = datos %>%
select(-"__index_level_0__") %>%
rename_with(~ str_replace(., "_%", ""), contains("_%")) %>%
mutate(mode = as.factor(mode)) %>%
select(-c(1:16))
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123) # Para reproducibilidad
particion_class = initial_split(datos_modelo_class, prop = 0.8)
datos_class_ent = training(particion_class)
datos_class_test = testing(particion_class)
# Definir especificaciones del modelo de regresión log_classística
log_class_spec = logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
# Crear una receta para preprocesar los datos
preprocesado_class = recipe(mode ~ ., datos_modelo_class) %>%
step_zv(all_numeric()) %>%
step_normalize(all_numeric())
# Definir el workflow que une la receta y el modelo
log_class_wfl = workflow() %>%
add_recipe(preprocesado_class) %>%
add_model(log_class_spec)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_class = vfold_cv(datos_class_ent, v = 10, strata = mode)
# Ajustar el modelo con validación cruzada en el conjunto de entrenamiento
resultados_log_class_cv = log_class_wfl %>%
fit_resamples(
resamples = cv_folds_class,
metrics = metric_set(roc_auc, accuracy)
)
# Recoger y mostrar las métricas de la validación cruzada
resultados_log_class_cv%>%
collect_metrics()
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_log_class_final=log_class_wfl %>%
last_fit(particion_class)
# Mostrar matriz de confusión
modelo_log_class_final %>%
collect_predictions() %>%
conf_mat(truth = mode, estimate = .pred_class)
# Mostrar métricas de clasificación
modelo_log_class_final %>%
collect_predictions() %>%
metrics(truth = mode, estimate = .pred_class)
# Generar y visualizar la curva ROC
modelo_log_class_final %>%
collect_predictions() %>%
roc_curve(truth = mode, .pred_Major) %>%
autoplot
# Cargar las bibliotecas necesarias
library(tidyverse)
library(arrow)
library(tidymodels)
library(tune)
library(kernlab)
library(dials)
# Leer los datos desde un archivo Feather
datos = read_feather("datos.feather")
# Preprocesar los datos
datos_modelo = datos %>%
select(-"__index_level_0__") %>%
rename_with(~ str_replace(., "_%", ""), contains("_%")) %>%
mutate(mode = as.factor(mode)) %>%
select(-c(1:16))
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123) # Para reproducibilidad
particion_class = initial_split(datos_modelo, prop = 0.8)
datos_class_ent = training(particion_class)
datos_class_test = testing(particion_class)
# Definir especificaciones del modelo svm_class con parámetros a tunear
svm_class_spec = svm_rbf(cost = tune(), rbf_sigma = tune()) %>%
set_engine("kernlab") %>%
set_mode("classification")
# Crear una receta para preprocesar los datos
preprocesado_class = recipe(mode ~ ., datos_modelo) %>%
step_zv(all_numeric()) %>%
step_normalize(all_numeric())
# Definir el workflow que une la receta y el modelo
svm_class_wfl = workflow() %>%
add_recipe(preprocesado_class) %>%
add_model(svm_class_spec)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_class = vfold_cv(datos_class_ent, v = 10, strata = mode)
cost_values = 10^seq(-3, 2, length.out = 5)
sigma_values = 10^seq(-3, 0, length.out = 5)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_svm_class = expand_grid(cost = cost_values, rbf_sigma = sigma_values)
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_svm_class_tune = svm_class_wfl %>%
tune_grid(
resamples = cv_folds_class,
grid = grid_svm_class,
metrics = metric_set(roc_auc, accuracy)
)
# Mostrar los resultados del ajuste de hiperparámetros
resultados_svm_class_tune %>%
collect_metrics()
svm_class_mejor=resultados_svm_class_tune %>%
select_best(metric="accuracy")
# Finalizar el modelo con los mejores hiperparámetros
svm_class_wfl_final = svm_class_wfl %>%
finalize_workflow(svm_class_mejor)
# Ajustar el modelo final en el conjunto de entrenamiento completo
modelo_svm_class_final = svm_class_wfl_final %>%
last_fit(particion_class)
# Mostrar matriz de confusión
modelo_svm_class_final %>%
collect_predictions() %>%
conf_mat(truth = mode, estimate = .pred_class)
# Mostrar métricas de clasificación
modelo_svm_class_final %>%
collect_predictions() %>%
metrics(truth = mode, estimate = .pred_class)
# Generar y visualizar la curva ROC
modelo_svm_class_final %>%
collect_predictions() %>%
roc_curve(truth = mode, .pred_Major) %>%
autoplot()
# Cargar las bibliotecas necesarias
library(tidyverse)
library(arrow)
library(tidymodels)
library(tune)
library(ranger)
library(dials)
# Leer los datos desde un archivo Feather
datos = read_feather("datos.feather")
# Preprocesar los datos
datos_modelo = datos %>%
select(-"__index_level_0__") %>%
rename_with(~ str_replace(., "_%", ""), contains("_%")) %>%
mutate(mode = as.factor(mode)) %>%
select(-c(1:16))
# Dividir los datos en conjuntos de entrenamiento y prueba
set.seed(123) # Para reproducibilidad
particion_class = initial_split(datos_modelo, prop = 0.8)
datos_entrenamiento = training(particion_class)
datos_prueba = testing(particion_class)
# Definir especificaciones del modelo Random Forest con parámetros a tunear
rf_class_spec = rand_forest(
mtry = tune(),
min_n = tune(),
trees = 1000  # Número de árboles fijo
) %>%
set_engine("randomForest") %>%
set_mode("classification")
# Crear una receta para preprocesar los datos
preprocesado_class = recipe(mode ~ ., datos_modelo) %>%
step_zv(all_numeric()) %>%
step_normalize(all_numeric())
# Definir el workflow que une la receta y el modelo
rf_class_wfl = workflow() %>%
add_recipe(preprocesado_class) %>%
add_model(rf_class_spec)
# Crear la validación cruzada en el conjunto de entrenamiento con 10 pliegues
cv_folds_class = vfold_cv(datos_entrenamiento, v = 10, strata = mode)
# Definir los rangos de hiperparámetros a explorar
mtry_values = seq(2, ncol(datos_entrenamiento) - 1, by = 2)
min_n_values = seq(2, 22, by = 4)
# Crear una cuadrícula de hiperparámetros usando expand_grid
grid_rf_class = expand_grid(mtry = mtry_values, min_n = min_n_values)
# Ajustar el modelo con validación cruzada y tunear los hiperparámetros
resultados_tune_rf_class = rf_class_wfl %>%
tune_grid(
resamples = cv_folds_class,
grid = grid_rf_class,
metrics = metric_set(roc_auc, accuracy)
)
