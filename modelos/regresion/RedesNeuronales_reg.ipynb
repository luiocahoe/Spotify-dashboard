{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300, Loss: 0.13202418386936188\n",
      "Epoch 20/300, Loss: 0.2934790849685669\n",
      "Epoch 30/300, Loss: 0.16379229724407196\n",
      "Epoch 40/300, Loss: 0.09083058685064316\n",
      "Epoch 50/300, Loss: 0.11154761910438538\n",
      "Epoch 60/300, Loss: 0.10939120501279831\n",
      "Epoch 70/300, Loss: 0.09772422164678574\n",
      "Epoch 80/300, Loss: 0.09612202644348145\n",
      "Epoch 90/300, Loss: 0.11120454221963882\n",
      "Epoch 100/300, Loss: 0.2430298924446106\n",
      "Epoch 110/300, Loss: 0.07989563792943954\n",
      "Epoch 120/300, Loss: 0.12170503288507462\n",
      "Epoch 130/300, Loss: 0.1595032662153244\n",
      "Epoch 140/300, Loss: 0.08169477432966232\n",
      "Epoch 150/300, Loss: 0.04864491894841194\n",
      "Epoch 160/300, Loss: 0.10377544164657593\n",
      "Epoch 170/300, Loss: 0.05672154948115349\n",
      "Epoch 180/300, Loss: 0.07346315681934357\n",
      "Epoch 190/300, Loss: 0.17206841707229614\n",
      "Epoch 200/300, Loss: 0.06297651678323746\n",
      "Epoch 210/300, Loss: 0.027060816064476967\n",
      "Epoch 220/300, Loss: 0.09915703535079956\n",
      "Epoch 230/300, Loss: 0.05215732380747795\n",
      "Epoch 240/300, Loss: 0.05722670629620552\n",
      "Epoch 250/300, Loss: 0.05754070356488228\n",
      "Epoch 260/300, Loss: 0.09125330299139023\n",
      "Epoch 270/300, Loss: 0.07321961969137192\n",
      "Epoch 280/300, Loss: 0.06779767572879791\n",
      "Epoch 290/300, Loss: 0.10575059801340103\n",
      "Epoch 300/300, Loss: 0.13764430582523346\n",
      "R^2 en el conjunto de prueba: 0.7051404752969722\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "datos = pd.read_feather(\"datos.feather\")\n",
    "columnas_a_eliminar = [\"released_year\", \"released_month\", \"released_day\", \"track_name\", \"artist(s)_name\"]\n",
    "data = datos.drop(columnas_a_eliminar, axis=1)\n",
    "\n",
    "data = pd.get_dummies(data)\n",
    "\n",
    "X = data.drop(\"streams\", axis=1).values\n",
    "y = data[\"streams\"].values.reshape(-1, 1)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, predictores, respuesta):\n",
    "        self.predictores = torch.tensor(predictores, dtype=torch.float32)\n",
    "        self.respuesta = torch.tensor(respuesta, dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.respuesta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.predictores[idx], self.respuesta[idx]\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train)\n",
    "test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Definici√≥n del Modelo\n",
    "class RegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "model = RegressionModel(input_dim)\n",
    "\n",
    "# Entrenamiento del Modelo\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 300\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for predictores, respuesta in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(predictores)\n",
    "        loss = criterion(outputs, respuesta)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "model.eval()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for predictores, respuesta in test_loader:\n",
    "        outputs = model(predictores)\n",
    "        y_true.extend(respuesta.numpy())\n",
    "        y_pred.extend(outputs.numpy())\n",
    "\n",
    "y_true = scaler_y.inverse_transform(y_true)\n",
    "y_pred = scaler_y.inverse_transform(y_pred)\n",
    "\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"R^2 en el conjunto de prueba: {r2}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
